{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لا حضرتك راجع الإعداد فى العالم حتلاقيها أكبر ...</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: كلام.المجلس.الاعلى.للخيانه والخرفانيه ينفع.ع...</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لا مش بتحبه ..ومش ممكن تخسر صديقة عمرها بنت عمها</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>شكرا ويارب كل الناس تكون بخير وربنا يرفع عنا و...</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>صح أخى عبدالله 👌👍</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>امين امين 🌹🌹🌹</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>ياااانهااااارررر ااااسود...الله يخربيت امريكا😡😡</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>تسلملي استاذ حسين🌹🌹</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>ورحمة الله. بالله عليكم اساتذتنا الكرام. استف...</td>\n",
       "      <td>اسره</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>: ولسه يا فندم ،، في نسخه البلتاجي التركيه ،، ...</td>\n",
       "      <td>شات</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     لا حضرتك راجع الإعداد فى العالم حتلاقيها أكبر ...   شات\n",
       "1     : كلام.المجلس.الاعلى.للخيانه والخرفانيه ينفع.ع...   شات\n",
       "2      لا مش بتحبه ..ومش ممكن تخسر صديقة عمرها بنت عمها   شات\n",
       "3     شكرا ويارب كل الناس تكون بخير وربنا يرفع عنا و...   شات\n",
       "4                                     صح أخى عبدالله 👌👍   شات\n",
       "...                                                 ...   ...\n",
       "9493                                      امين امين 🌹🌹🌹   شات\n",
       "9494    ياااانهااااارررر ااااسود...الله يخربيت امريكا😡😡   شات\n",
       "9495                                تسلملي استاذ حسين🌹🌹   شات\n",
       "9496   ورحمة الله. بالله عليكم اساتذتنا الكرام. استف...  اسره\n",
       "9497  : ولسه يا فندم ،، في نسخه البلتاجي التركيه ،، ...   شات\n",
       "\n",
       "[9498 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "dataset=pd.read_excel('ruleBased.xlsx')\n",
    "import arabicstopwords.arabicstopwords as asw\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split,KFold, StratifiedKFold, LeaveOneOut, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'شات', 'قضيه'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling code\n",
    "\n",
    "# df = pd.DataFrame(dataset)\n",
    "# df = df.sample(frac=1, random_state=42)\n",
    "# print(df)\n",
    "# df=pd.DataFrame(df)\n",
    "# df.to_excel('ruleBased.xlsx', index=False)\n",
    "dataset.label=dataset.label.replace('اسره','قضيه')\n",
    "dataset.label=dataset.label.replace('جنح','قضيه')\n",
    "dataset.label=dataset.label.replace('مدني','قضيه')\n",
    "set(dataset.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remve_noise(cases):\n",
    "    corpus=[]\n",
    "    for case in cases:\n",
    "        s=case.lower()\n",
    "        s=re.sub(\"[0-9]\",'',s)\n",
    "        words=word_tokenize(s)\n",
    "        word=[w for w in words if w not in asw.stopwords_list() if w not in string.punctuation]\n",
    "        s=\" \".join(word)\n",
    "        corpus.append(s)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(remve_noise(dataset['text']))\n",
    "X = tfidf_vectorizer.transform(remve_noise(dataset['text']))\n",
    "Y=dataset['label']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X.toarray(),columns=sorted(tfidf_vectorizer.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "sig = svm.SVC(kernel='sigmoid').fit(X_train, Y_train)\n",
    "\n",
    "liner_SVM = LinearSVC()\n",
    "liner_SVM.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_pred = sig.predict(X_test)\n",
    "\n",
    "linersvm_pred=liner_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1483    5]\n",
      " [  17  395]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,sig_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1484    4]\n",
      " [  21  391]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,linersvm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is as sig  0.988421052631579\n",
      "accuracy is as linear SVM  0.9868421052631579\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is as sig \",accuracy_score(Y_test, sig_pred))\n",
    "print(\"accuracy is as linear SVM \",accuracy_score(Y_test, linersvm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         شات       0.99      1.00      0.99      1488\n",
      "        قضيه       0.99      0.96      0.97       412\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.98      0.98      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,sig_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         شات       0.99      1.00      0.99      1488\n",
      "        قضيه       0.99      0.95      0.97       412\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.97      0.98      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, linersvm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sig, open('ruleBased.pkl', 'wb'))\n",
    "pickle.dump(tfidf_vectorizer, open('ruleBasedTokenizer.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruleBased(text):\n",
    "    text=[text]\n",
    "    transform=tfidf_vectorizer.transform(remve_noise(text))\n",
    "    pickled_model=pickle.load(open('ruleBased.pkl','rb'))\n",
    "    return(pickled_model.predict(transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['شات'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruleBased('مال')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
